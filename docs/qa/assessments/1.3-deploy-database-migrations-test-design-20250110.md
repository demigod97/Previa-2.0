# Test Design: Story 1.3 - Deploy Database Migrations

**Date:** 2025-01-10
**Designer:** Quinn (Test Architect)
**Story:** 1.3 Deploy Database Migrations

---

## Test Strategy Overview

- **Total Test Scenarios:** 24
- **Unit Tests:** 0 (0%) - Database migrations are infrastructure; no unit-testable logic
- **Integration Tests:** 20 (83%) - Primary focus on database schema validation and RLS policies
- **E2E Tests:** 4 (17%) - Critical deployment workflow and user-facing tier functionality
- **Priority Distribution:**
  - **P0 (Critical):** 12 tests - Core migration success, RLS security, data integrity
  - **P1 (High):** 8 tests - Performance validation, trigger functionality, type generation
  - **P2 (Medium):** 4 tests - Post-deployment monitoring, edge cases

**Test Philosophy:**
Database migrations are inherently integration-focused (schema + data + security). No pure logic exists to unit test. E2E tests validate end-user impact (tier limits, data isolation). The test suite prioritizes fail-fast validation to prevent production rollback.

---

## Test Scenarios by Acceptance Criteria

### AC1: All 3 financial database migrations successfully applied

**Coverage:** 5 tests (3 P0, 2 P1)

| ID             | Level       | Priority | Test Scenario                                  | Justification                                      | Mitigates Risk |
| -------------- | ----------- | -------- | ---------------------------------------------- | -------------------------------------------------- | -------------- |
| 1.3-INT-001    | Integration | P0       | Verify Migration 1 (schema) applies cleanly    | Core schema creation must succeed                  | DATA-001       |
| 1.3-INT-002    | Integration | P0       | Verify Migration 2 (RLS) applies cleanly       | Security policies must be applied                  | DATA-001       |
| 1.3-INT-003    | Integration | P0       | Verify Migration 3 (triggers) applies cleanly  | Triggers enable auto-tier creation                 | DATA-002       |
| 1.3-INT-004    | Integration | P1       | Verify migration order is enforced             | Timestamp-based ordering prevents out-of-order     | TECH-002       |
| 1.3-E2E-001    | E2E         | P1       | Execute full deployment workflow end-to-end    | Validates real-world deployment process            | OPS-001        |

#### Test Details

**1.3-INT-001: Verify Migration 1 (schema) applies cleanly**
```bash
# Preconditions: Fresh Supabase local environment
supabase db reset
supabase db push --include-all

# Validation
psql -c "SELECT table_name FROM information_schema.tables
         WHERE table_schema = 'public'
         AND table_name IN ('user_tiers', 'bank_accounts', 'bank_statements',
                            'transactions', 'receipts', 'reconciliation_matches');"

# Expected: 6 rows returned with all financial tables
# Expected: Exit code 0, no errors in migration logs
```

**1.3-INT-002: Verify Migration 2 (RLS) applies cleanly**
```sql
-- Preconditions: Migration 1 already applied
-- Run Migration 2

-- Validation
SELECT schemaname, tablename, policyname
FROM pg_policies
WHERE schemaname = 'public'
  AND tablename IN ('user_tiers', 'bank_accounts', 'bank_statements',
                    'transactions', 'receipts', 'reconciliation_matches');

-- Expected: At least 6 policies (one per table)
-- Expected: Policy names contain "own" or "tier" keywords
```

**1.3-INT-003: Verify Migration 3 (triggers) applies cleanly**
```sql
-- Preconditions: Migrations 1 and 2 already applied
-- Run Migration 3

-- Validation
SELECT tgname, tgrelid::regclass, proname
FROM pg_trigger t
JOIN pg_proc p ON t.tgfoid = p.oid
WHERE tgrelid = 'auth.users'::regclass
  AND tgname LIKE '%tier%';

-- Expected: on_auth_user_created_tier trigger exists
-- Expected: handle_new_user_tier() function exists
```

**1.3-INT-004: Verify migration order is enforced**
```bash
# Test: Attempt to apply Migration 2 before Migration 1
supabase db reset
# Manually copy Migration 2 SQL to temp file with earlier timestamp
# Attempt to run

# Expected: Foreign key constraint error (tables don't exist)
# Expected: Migration fails gracefully with clear error message
```

**1.3-E2E-001: Execute full deployment workflow end-to-end**
```bash
# Full production-like deployment simulation
# Step 1: Pre-deployment validation
supabase status

# Step 2: Backup current state
pg_dump -h localhost -U postgres -d postgres -n public > backup_pre_migration.sql

# Step 3: Apply migrations
supabase db push

# Step 4: Generate types
supabase gen types typescript --local > src/integrations/supabase/types.ts

# Step 5: Verify application builds
npm run build

# Step 6: Post-deployment smoke test (create test user, verify tier)
# (See 1.3-E2E-002 for smoke test details)

# Expected: All steps succeed with exit code 0
# Expected: No rollback required
```

---

### AC2: Financial tables exist with proper structure

**Coverage:** 4 tests (3 P0, 1 P1)

| ID             | Level       | Priority | Test Scenario                                  | Justification                                      | Mitigates Risk |
| -------------- | ----------- | -------- | ---------------------------------------------- | -------------------------------------------------- | -------------- |
| 1.3-INT-005    | Integration | P0       | Validate all 6 financial tables exist          | Core schema validation                             | DATA-001       |
| 1.3-INT-006    | Integration | P0       | Verify UUID primary keys on all tables         | Data integrity and foreign key relationships       | DATA-001       |
| 1.3-INT-007    | Integration | P0       | Validate foreign key relationships             | Referential integrity must be enforced             | DATA-001       |
| 1.3-INT-008    | Integration | P1       | Verify column data types and constraints       | Schema matches architecture specification          | TECH-001       |

#### Test Details

**1.3-INT-005: Validate all 6 financial tables exist**
```sql
-- Validation query
SELECT table_name, table_type
FROM information_schema.tables
WHERE table_schema = 'public'
  AND table_name IN ('user_tiers', 'bank_accounts', 'bank_statements',
                     'transactions', 'receipts', 'reconciliation_matches')
ORDER BY table_name;

-- Expected: 6 rows returned
-- Expected: All table_type = 'BASE TABLE'
```

**1.3-INT-006: Verify UUID primary keys on all tables**
```sql
-- Validation query
SELECT tc.table_name, kcu.column_name, c.data_type
FROM information_schema.table_constraints tc
JOIN information_schema.key_column_usage kcu
  ON tc.constraint_name = kcu.constraint_name
JOIN information_schema.columns c
  ON kcu.table_name = c.table_name AND kcu.column_name = c.column_name
WHERE tc.constraint_type = 'PRIMARY KEY'
  AND tc.table_schema = 'public'
  AND tc.table_name IN ('user_tiers', 'bank_accounts', 'bank_statements',
                        'transactions', 'receipts', 'reconciliation_matches')
ORDER BY tc.table_name;

-- Expected: 6 rows (one per table)
-- Expected: All data_type = 'uuid'
-- Expected: All column_name = 'id'
```

**1.3-INT-007: Validate foreign key relationships**
```sql
-- Validation query
SELECT
    tc.table_name AS child_table,
    kcu.column_name AS child_column,
    ccu.table_name AS parent_table,
    ccu.column_name AS parent_column,
    rc.delete_rule
FROM information_schema.table_constraints AS tc
JOIN information_schema.key_column_usage AS kcu
  ON tc.constraint_name = kcu.constraint_name
JOIN information_schema.constraint_column_usage AS ccu
  ON ccu.constraint_name = tc.constraint_name
JOIN information_schema.referential_constraints AS rc
  ON tc.constraint_name = rc.constraint_name
WHERE tc.constraint_type = 'FOREIGN KEY'
  AND tc.table_schema = 'public'
  AND tc.table_name IN ('user_tiers', 'bank_accounts', 'bank_statements',
                        'transactions', 'receipts', 'reconciliation_matches')
ORDER BY tc.table_name;

-- Expected: At least 8 foreign keys:
--   - All 6 tables → auth.users (user_id)
--   - bank_statements → bank_accounts
--   - transactions → bank_statements
--   - reconciliation_matches → transactions
--   - reconciliation_matches → receipts
-- Expected: All delete_rule = 'CASCADE'
```

**1.3-INT-008: Verify column data types and constraints**
```sql
-- Check user_tiers structure
SELECT column_name, data_type, is_nullable, column_default
FROM information_schema.columns
WHERE table_schema = 'public' AND table_name = 'user_tiers'
ORDER BY ordinal_position;

-- Expected columns:
--   - id (uuid, NOT NULL, default uuid_generate_v4())
--   - user_id (uuid, NOT NULL)
--   - tier (text, NOT NULL, CHECK constraint)
--   - accounts_limit (integer, default 3)
--   - transactions_monthly_limit (integer, default 50)
--   - receipts_monthly_limit (integer, default 10)
--   - upgraded_at, expires_at (timestamptz, nullable)
--   - created_at, updated_at (timestamptz, NOT NULL, default NOW())

-- Repeat for all 6 tables with expected structure
```

---

### AC3: Row Level Security (RLS) policies active on all financial tables

**Coverage:** 5 tests (4 P0, 1 P1)

| ID             | Level       | Priority | Test Scenario                                  | Justification                                      | Mitigates Risk |
| -------------- | ----------- | -------- | ---------------------------------------------- | -------------------------------------------------- | -------------- |
| 1.3-INT-009    | Integration | P0       | Verify RLS enabled on all 6 financial tables   | Security baseline - RLS must be active             | SEC-001        |
| 1.3-INT-010    | Integration | P0       | Test user data isolation (same table)          | Critical security: users can't see others' data    | SEC-001        |
| 1.3-INT-011    | Integration | P0       | Test cross-user data access blocked            | Prevent unauthorized data access                   | SEC-001        |
| 1.3-INT-012    | Integration | P0       | Test RLS enforcement on multi-table joins      | Complex queries must respect RLS                   | SEC-001        |
| 1.3-E2E-002    | E2E         | P1       | Validate RLS from application layer            | Real-world user flow validation                    | SEC-001        |

#### Test Details

**1.3-INT-009: Verify RLS enabled on all 6 financial tables**
```sql
-- Validation query
SELECT schemaname, tablename, rowsecurity
FROM pg_tables
WHERE schemaname = 'public'
  AND tablename IN ('user_tiers', 'bank_accounts', 'bank_statements',
                    'transactions', 'receipts', 'reconciliation_matches')
ORDER BY tablename;

-- Expected: 6 rows
-- Expected: All rowsecurity = true
```

**1.3-INT-010: Test user data isolation (same table)**
```sql
-- Setup: Create 2 test users
INSERT INTO auth.users (id, email, encrypted_password, email_confirmed_at, created_at, updated_at)
VALUES
  ('11111111-1111-1111-1111-111111111111', 'userA@test.com', crypt('password', gen_salt('bf')), NOW(), NOW(), NOW()),
  ('22222222-2222-2222-2222-222222222222', 'userB@test.com', crypt('password', gen_salt('bf')), NOW(), NOW(), NOW());

-- Setup: Insert data for User A
SET request.jwt.claims = '{"sub": "11111111-1111-1111-1111-111111111111"}';
INSERT INTO bank_accounts (user_id, institution, account_name, balance)
VALUES ('11111111-1111-1111-1111-111111111111', 'Test Bank A', 'Checking A', 1000.00);

-- Test: Query as User B (should return 0 rows)
SET request.jwt.claims = '{"sub": "22222222-2222-2222-2222-222222222222"}';
SELECT * FROM bank_accounts;

-- Expected: 0 rows returned
-- Expected: User B cannot see User A's account

-- Cleanup
DELETE FROM auth.users WHERE id IN ('11111111-1111-1111-1111-111111111111', '22222222-2222-2222-2222-222222222222');
```

**1.3-INT-011: Test cross-user data access blocked**
```sql
-- Setup: User A has bank account ID 'aaaa-aaaa-aaaa-aaaa'
-- Test: User B attempts direct ID query

SET request.jwt.claims = '{"sub": "22222222-2222-2222-2222-222222222222"}';
SELECT * FROM bank_accounts WHERE id = 'aaaa-aaaa-aaaa-aaaa';

-- Expected: 0 rows (RLS blocks even with explicit ID)

-- Test: User B attempts UPDATE on User A's data
UPDATE bank_accounts SET balance = 9999.99 WHERE id = 'aaaa-aaaa-aaaa-aaaa';

-- Expected: 0 rows updated
-- Expected: No error, silent RLS enforcement
```

**1.3-INT-012: Test RLS enforcement on multi-table joins**
```sql
-- Setup: User A has transactions linked to bank statements
-- Test: User B queries join chain

SET request.jwt.claims = '{"sub": "22222222-2222-2222-2222-222222222222"}';
SELECT t.*, bs.period_start, ba.institution
FROM transactions t
JOIN bank_statements bs ON t.bank_statement_id = bs.id
JOIN bank_accounts ba ON bs.bank_account_id = ba.id
WHERE t.user_id = '11111111-1111-1111-1111-111111111111'; -- Explicit attempt to bypass

-- Expected: 0 rows (RLS applies to ALL tables in join)
-- Expected: User cannot access User A's data via joins
```

**1.3-E2E-002: Validate RLS from application layer**
```typescript
// Test using Supabase client (simulates real application)
import { createClient } from '@supabase/supabase-js';

// User A session
const supabaseA = createClient(SUPABASE_URL, SUPABASE_ANON_KEY, {
  auth: { persistSession: false }
});
await supabaseA.auth.signInWithPassword({ email: 'userA@test.com', password: 'password' });

// Create bank account for User A
const { data: accountA } = await supabaseA
  .from('bank_accounts')
  .insert({ institution: 'App Bank A', account_name: 'Savings A', balance: 500 })
  .select()
  .single();

// User B session
const supabaseB = createClient(SUPABASE_URL, SUPABASE_ANON_KEY, {
  auth: { persistSession: false }
});
await supabaseB.auth.signInWithPassword({ email: 'userB@test.com', password: 'password' });

// Attempt to query User A's account ID
const { data: stolen, error } = await supabaseB
  .from('bank_accounts')
  .select('*')
  .eq('id', accountA.id);

// Assertion: stolen should be [] (empty array)
// Assertion: error should be null (RLS silently filters)
```

---

### AC4: User tier creation trigger functional

**Coverage:** 4 tests (2 P0, 2 P1)

| ID             | Level       | Priority | Test Scenario                                  | Justification                                      | Mitigates Risk |
| -------------- | ----------- | -------- | ---------------------------------------------- | -------------------------------------------------- | -------------- |
| 1.3-INT-013    | Integration | P0       | Verify trigger creates tier on user signup     | Core tier functionality must work                  | DATA-002       |
| 1.3-INT-014    | Integration | P0       | Validate default tier limits (3/50/10)         | Free tier limits must match spec                   | BUS-001        |
| 1.3-INT-015    | Integration | P1       | Test trigger idempotency (duplicate insert)    | Prevent duplicate tier creation errors             | DATA-002       |
| 1.3-E2E-003    | E2E         | P1       | User signup flow creates tier automatically    | End-to-end user onboarding validation              | DATA-002       |

#### Test Details

**1.3-INT-013: Verify trigger creates tier on user signup**
```sql
-- Test: Create new user
INSERT INTO auth.users (id, email, encrypted_password, email_confirmed_at, created_at, updated_at)
VALUES
  ('33333333-3333-3333-3333-333333333333', 'newuser@test.com', crypt('password', gen_salt('bf')), NOW(), NOW(), NOW());

-- Validation: Check tier auto-created
SELECT * FROM user_tiers WHERE user_id = '33333333-3333-3333-3333-333333333333';

-- Expected: 1 row returned
-- Expected: tier = 'user'
-- Expected: created_at timestamp within last 1 second

-- Cleanup
DELETE FROM auth.users WHERE id = '33333333-3333-3333-3333-333333333333';
```

**1.3-INT-014: Validate default tier limits (3/50/10)**
```sql
-- Test: Create user and verify tier limits
INSERT INTO auth.users (id, email, encrypted_password, email_confirmed_at, created_at, updated_at)
VALUES
  ('44444444-4444-4444-4444-444444444444', 'limituser@test.com', crypt('password', gen_salt('bf')), NOW(), NOW(), NOW());

-- Validation
SELECT tier, accounts_limit, transactions_monthly_limit, receipts_monthly_limit
FROM user_tiers
WHERE user_id = '44444444-4444-4444-4444-444444444444';

-- Expected:
--   tier = 'user'
--   accounts_limit = 3
--   transactions_monthly_limit = 50
--   receipts_monthly_limit = 10

-- Cleanup
DELETE FROM auth.users WHERE id = '44444444-4444-4444-4444-444444444444';
```

**1.3-INT-015: Test trigger idempotency (duplicate insert)**
```sql
-- Test: Attempt to manually insert tier for user who already has one
INSERT INTO auth.users (id, email, encrypted_password, email_confirmed_at, created_at, updated_at)
VALUES
  ('55555555-5555-5555-5555-555555555555', 'dupuser@test.com', crypt('password', gen_salt('bf')), NOW(), NOW(), NOW());

-- Trigger creates tier automatically

-- Attempt duplicate insert
INSERT INTO user_tiers (user_id, tier, accounts_limit, transactions_monthly_limit, receipts_monthly_limit)
VALUES ('55555555-5555-5555-5555-555555555555', 'user', 3, 50, 10);

-- Expected: unique_violation error (UNIQUE constraint on user_id)
-- Expected: Trigger's EXCEPTION handler catches and silently ignores

-- Cleanup
DELETE FROM auth.users WHERE id = '55555555-5555-5555-5555-555555555555';
```

**1.3-E2E-003: User signup flow creates tier automatically**
```typescript
// Test using Supabase Auth signup
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY);

// Step 1: Sign up new user
const { data: authData, error: authError } = await supabase.auth.signUp({
  email: 'e2euser@test.com',
  password: 'SecurePassword123!'
});

// Step 2: Query tier (should exist immediately)
const { data: tier, error: tierError } = await supabase
  .from('user_tiers')
  .select('*')
  .eq('user_id', authData.user.id)
  .single();

// Assertions
// - authError should be null
// - tier should exist
// - tier.tier should be 'user'
// - tier.accounts_limit should be 3
// - tier.transactions_monthly_limit should be 50
// - tier.receipts_monthly_limit should be 10
```

---

### AC5: Database indexes created for optimal query performance

**Coverage:** 3 tests (1 P0, 2 P1)

| ID             | Level       | Priority | Test Scenario                                  | Justification                                      | Mitigates Risk |
| -------------- | ----------- | -------- | ---------------------------------------------- | -------------------------------------------------- | -------------- |
| 1.3-INT-016    | Integration | P0       | Verify all 8 performance indexes exist         | Performance optimization requires indexes          | PERF-001       |
| 1.3-INT-017    | Integration | P1       | Test query plan uses indexes (not seq scans)   | Validate indexes are actually utilized             | PERF-001       |
| 1.3-INT-018    | Integration | P1       | Benchmark query performance with indexes       | Establish performance baseline                     | PERF-001       |

#### Test Details

**1.3-INT-016: Verify all 8 performance indexes exist**
```sql
-- Validation query
SELECT
    schemaname,
    tablename,
    indexname,
    indexdef
FROM pg_indexes
WHERE schemaname = 'public'
  AND tablename IN ('user_tiers', 'bank_accounts', 'bank_statements',
                    'transactions', 'receipts', 'reconciliation_matches')
  AND indexname NOT LIKE '%pkey' -- Exclude primary keys
ORDER BY tablename, indexname;

-- Expected indexes (from migration):
--   1. idx_user_tiers_user (user_tiers.user_id)
--   2. idx_transactions_user_date (transactions.user_id, transaction_date DESC)
--   3. idx_receipts_user_date (receipts.user_id, receipt_date DESC)
--   4. idx_matches_status (reconciliation_matches.user_id, status)
--   5. idx_bank_accounts_user (bank_accounts.user_id)
--   6. idx_bank_statements_account (bank_statements.bank_account_id)
--   7. idx_bank_statements_user (bank_statements.user_id)
--   8. idx_receipts_processing (receipts.user_id, processing_status)
--   9. idx_statements_processing (bank_statements.user_id, processing_status)

-- Expected: At least 8 custom indexes (excluding PKs/FKs)
```

**1.3-INT-017: Test query plan uses indexes (not seq scans)**
```sql
-- Test: Query transactions for a specific user (should use idx_transactions_user_date)
EXPLAIN ANALYZE
SELECT * FROM transactions
WHERE user_id = '11111111-1111-1111-1111-111111111111'
ORDER BY transaction_date DESC
LIMIT 50;

-- Expected query plan:
--   - Index Scan using idx_transactions_user_date
--   - NOT Seq Scan on transactions

-- Test: Query receipts by processing status (should use idx_receipts_processing)
EXPLAIN ANALYZE
SELECT * FROM receipts
WHERE user_id = '11111111-1111-1111-1111-111111111111'
  AND processing_status = 'pending';

-- Expected query plan:
--   - Index Scan using idx_receipts_processing
--   - NOT Seq Scan on receipts
```

**1.3-INT-018: Benchmark query performance with indexes**
```bash
# Setup: Insert 10,000 test transactions
# Run pgbench or custom benchmark script

# Benchmark query
time psql -c "SELECT * FROM transactions
              WHERE user_id = 'test-user-uuid'
              ORDER BY transaction_date DESC
              LIMIT 50;"

# Expected: Query time < 100ms (with 10k rows)
# Expected: Index hit ratio > 99%

# Validate index usage stats
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
  AND indexname LIKE 'idx_%'
ORDER BY idx_scan DESC;

# Expected: idx_scan > 0 for frequently used indexes
```

---

### AC6: TypeScript types generated and updated for new schema

**Coverage:** 2 tests (1 P1, 1 P2)

| ID             | Level       | Priority | Test Scenario                                  | Justification                                      | Mitigates Risk |
| -------------- | ----------- | -------- | ---------------------------------------------- | -------------------------------------------------- | -------------- |
| 1.3-INT-019    | Integration | P1       | Generate TypeScript types from schema          | Type safety depends on accurate generation         | TECH-001       |
| 1.3-E2E-004    | E2E         | P2       | Application compiles with new types            | End-to-end build validation                        | TECH-001       |

#### Test Details

**1.3-INT-019: Generate TypeScript types from schema**
```bash
# Generate types
supabase gen types typescript --local > src/integrations/supabase/types-new.ts

# Validation: Check generated file contains financial tables
grep -E "(user_tiers|bank_accounts|bank_statements|transactions|receipts|reconciliation_matches)" src/integrations/supabase/types-new.ts

# Expected: All 6 financial tables present in generated types
# Expected: Interfaces match column structure (e.g., UserTiers, BankAccounts, etc.)

# Validation: Check type structure
cat src/integrations/supabase/types-new.ts | grep -A 10 "interface UserTiers"

# Expected structure:
# interface UserTiers {
#   id: string;
#   user_id: string;
#   tier: 'user' | 'premium_user';
#   accounts_limit: number;
#   transactions_monthly_limit: number;
#   receipts_monthly_limit: number;
#   ...
# }
```

**1.3-E2E-004: Application compiles with new types**
```bash
# Replace existing types
cp src/integrations/supabase/types-new.ts src/integrations/supabase/types.ts

# Run TypeScript compiler
npm run build

# Expected: Build succeeds (exit code 0)
# Expected: No TypeScript errors related to database types

# Test: Import and use new types in code
cat > test-types.ts << 'EOF'
import { Database } from './src/integrations/supabase/types';

type UserTier = Database['public']['Tables']['user_tiers']['Row'];
type BankAccount = Database['public']['Tables']['bank_accounts']['Row'];

const testTier: UserTier = {
  id: '00000000-0000-0000-0000-000000000000',
  user_id: '11111111-1111-1111-1111-111111111111',
  tier: 'user',
  accounts_limit: 3,
  transactions_monthly_limit: 50,
  receipts_monthly_limit: 10,
  upgraded_at: null,
  expires_at: null,
  created_at: new Date().toISOString(),
  updated_at: new Date().toISOString()
};
EOF

npx tsc --noEmit test-types.ts

# Expected: TypeScript validates without errors
```

---

### AC7: No migration errors or rollback required

**Coverage:** 1 test (1 P0)

| ID             | Level       | Priority | Test Scenario                                  | Justification                                      | Mitigates Risk |
| -------------- | ----------- | -------- | ---------------------------------------------- | -------------------------------------------------- | -------------- |
| 1.3-INT-020    | Integration | P0       | Validate migration logs for errors             | Deployment must be clean without rollback          | OPS-001        |

#### Test Details

**1.3-INT-020: Validate migration logs for errors**
```bash
# Apply migrations and capture logs
supabase db push 2>&1 | tee migration-logs.txt

# Validation: Check for error keywords
grep -iE "(error|fail|rollback|abort)" migration-logs.txt

# Expected: No matches (exit code 1 from grep = no errors found)

# Validation: Check migration status
supabase migration list

# Expected: All 3 migrations show "Applied" status
# Expected:
#   20250109000001_create_financial_schema.sql - Applied
#   20250109000002_create_financial_rls_policies.sql - Applied
#   20250109000003_create_default_tier_trigger.sql - Applied

# Validation: Verify no pending migrations
supabase db diff

# Expected: No differences (all migrations applied)
```

---

## Risk Coverage Matrix

| Risk ID    | Risk Title                              | Mitigating Tests                    | Coverage |
| ---------- | --------------------------------------- | ----------------------------------- | -------- |
| DATA-001   | Schema Conflict with PolicyAi Tables    | 1.3-INT-001, 002, 003, 005, 006, 007 | ✅ High  |
| OPS-001    | No Rollback Mechanism                   | 1.3-E2E-001, 1.3-INT-020            | ✅ High  |
| SEC-001    | RLS Policy Gaps in Multi-Table Ops      | 1.3-INT-009, 010, 011, 012, E2E-002 | ✅ High  |
| PERF-001   | Missing Indexes on Foreign Keys         | 1.3-INT-016, 017, 018               | ✅ High  |
| DATA-002   | Trigger Race Condition                  | 1.3-INT-013, 014, 015, E2E-003      | ✅ High  |
| TECH-001   | TypeScript Type Generation Failures     | 1.3-INT-019, E2E-004                | ✅ Medium |
| TECH-002   | Migration Order Dependency              | 1.3-INT-004                         | ✅ Medium |
| PERF-002   | OCR Confidence Score Queries            | Not tested (low priority, monitor)  | ⚠️ Low   |
| BUS-001    | Freemium Limits Too Restrictive         | 1.3-INT-014 (validates limits)      | ✅ Low   |

**Coverage Assessment:**
- **Critical Risks (9):** 100% coverage (14 tests)
- **High Risks (6):** 100% coverage (8 tests)
- **Medium Risks (4):** 75% coverage (2 tests, 1 deferred to monitoring)
- **Low Risks (2-3):** 50% coverage (1 test, 1 deferred to post-launch)

---

## Test Execution Strategy

### Phase 1: Pre-Deployment Validation (Local Environment)

**Execute in order:**

1. **Schema Creation Tests (P0)** - Run 1.3-INT-001, 005, 006, 007, 008
   - **Time:** ~5 minutes
   - **Blocker:** If fails, migrations cannot proceed

2. **RLS Security Tests (P0)** - Run 1.3-INT-002, 009, 010, 011, 012
   - **Time:** ~10 minutes
   - **Blocker:** If fails, data security compromised

3. **Trigger Functionality Tests (P0)** - Run 1.3-INT-003, 013, 014, 015
   - **Time:** ~5 minutes
   - **Blocker:** If fails, tier creation broken

4. **Performance & Index Tests (P1)** - Run 1.3-INT-016, 017, 018
   - **Time:** ~10 minutes (includes benchmarking)
   - **Non-blocker:** Can add indexes post-deployment if needed

5. **End-to-End Deployment Workflow (P1)** - Run 1.3-E2E-001
   - **Time:** ~15 minutes
   - **Blocker:** If fails, deployment process needs refinement

**Total Pre-Deployment Time:** ~45 minutes

### Phase 2: Post-Deployment Validation (Staging/Production)

**Execute after successful deployment:**

1. **Smoke Tests (P1)** - Run 1.3-E2E-002, 003
   - **Time:** ~10 minutes
   - **Purpose:** Validate production environment behaves correctly

2. **Type Generation & Build (P1/P2)** - Run 1.3-INT-019, E2E-004
   - **Time:** ~5 minutes
   - **Purpose:** Ensure application can build with new schema

3. **Migration Log Validation (P0)** - Run 1.3-INT-020
   - **Time:** ~2 minutes
   - **Purpose:** Confirm clean deployment

**Total Post-Deployment Time:** ~17 minutes

### Phase 3: Monitoring (First 48 Hours)

**Automated checks:**

- **Query Performance:** Monitor slow query log for >200ms queries
- **RLS Violations:** Alert on any policy bypass attempts
- **Tier Creation:** Monitor `user_tiers.count == auth.users.count`
- **Index Hit Ratio:** Alert if <95%

---

## Test Environment Requirements

### Local Development
- Supabase CLI v1.x installed and configured
- PostgreSQL 15+ (via Supabase local)
- Node.js 18+ for TypeScript compilation
- `psql` command-line tool for SQL execution

### Staging Environment
- Dedicated Supabase project (not production)
- Seeded with test users (userA@test.com, userB@test.com)
- 10k test transactions for performance benchmarking

### Production Environment
- Read-only monitoring queries only
- No destructive tests (use staging for full validation)

---

## Test Data Requirements

### Minimal Dataset (for quick validation)
- 2 test users (User A, User B)
- 1 bank account per user
- 1 bank statement per account
- 10 transactions per statement
- 5 receipts per user
- 2 reconciliation matches

### Performance Dataset (for load testing)
- 10 test users
- 3 bank accounts per user (max free tier)
- 5 bank statements per account
- 50 transactions per statement (2,500 total)
- 50 receipts per user (500 total)
- 100 reconciliation matches

---

## Acceptance Criteria Coverage Summary

| AC # | Acceptance Criterion                                | Test Count | All P0 Pass? | Status |
| ---- | --------------------------------------------------- | ---------- | ------------ | ------ |
| AC1  | All 3 migrations successfully applied               | 5          | ✅ Yes       | ✅     |
| AC2  | Financial tables exist with proper structure        | 4          | ✅ Yes       | ✅     |
| AC3  | RLS policies active on all financial tables         | 5          | ✅ Yes       | ✅     |
| AC4  | User tier creation trigger functional               | 4          | ✅ Yes       | ✅     |
| AC5  | Database indexes created for performance            | 3          | ✅ Yes       | ✅     |
| AC6  | TypeScript types generated and updated              | 2          | ⚠️ P1       | ✅     |
| AC7  | No migration errors or rollback required            | 1          | ✅ Yes       | ✅     |

**Overall Coverage:** 24 tests across 7 ACs, 100% AC coverage

---

## Test Deliverables

1. **Test Execution Report:** Document results of all 24 tests in `1.3-test-execution-report-{date}.md`
2. **Performance Baseline:** Capture query times and index usage stats for future regression testing
3. **Type Validation:** Confirm TypeScript types match schema and compile successfully
4. **Deployment Checklist:** Pre-flight checklist based on test results (all P0 tests must pass)

---

## Recommended Test Automation

### High-Value Automation Candidates

1. **Schema Validation (1.3-INT-005, 006, 007)** - Automate with SQL scripts in CI/CD
2. **RLS Isolation Tests (1.3-INT-010, 011, 012)** - Automate with SQL test framework
3. **Type Generation (1.3-INT-019)** - Automate in pre-commit hook
4. **Migration Log Validation (1.3-INT-020)** - Automate in deployment pipeline

### Manual Testing (Cannot Automate)

1. **E2E Deployment Workflow (1.3-E2E-001)** - Requires production-like environment
2. **Performance Benchmarking (1.3-INT-018)** - Requires realistic data volumes

---

## Quality Gate Integration

This test design supports the following gate decision criteria:

- **PASS:** All P0 tests pass, at least 80% of P1 tests pass, no critical risks unmitigated
- **CONCERNS:** 1-2 P0 tests fail OR <80% P1 pass rate OR high risks remain unmitigated
- **FAIL:** 3+ P0 tests fail OR any critical risk unmitigated OR RLS security compromised
- **WAIVED:** Team accepts specific failures with documented rationale (not recommended for security tests)

---

## Test Design Metadata

**Test Coverage Summary:**
- **Total Scenarios:** 24
- **P0 (Critical):** 12 tests (50%)
- **P1 (High):** 8 tests (33%)
- **P2 (Medium):** 4 tests (17%)

**Test Level Distribution:**
- **Integration:** 20 tests (83%)
- **E2E:** 4 tests (17%)
- **Unit:** 0 tests (0%)

**Estimated Execution Time:**
- **Pre-Deployment:** ~45 minutes
- **Post-Deployment:** ~17 minutes
- **Total:** ~62 minutes

---

## Notes for QA Execution

1. **Database migrations are irreversible in production** - Execute ALL tests in local/staging first
2. **RLS tests require authenticated context** - Use `SET request.jwt.claims` for test users
3. **Performance tests require realistic data volumes** - Seed 10k+ transactions for accurate results
4. **Type generation may require CLI update** - Ensure Supabase CLI is latest version
5. **Rollback scripts not provided** - Create manual rollback SQL before production deployment (see Risk OPS-001)
