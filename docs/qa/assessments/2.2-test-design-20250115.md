# Test Design: Story 2.2 - Bank Statement Upload & OCR

Date: 2025-01-15
Designer: Quinn (Test Architect)

## Test Strategy Overview

- Total test scenarios: 47
- Unit tests: 18 (38%)
- Integration tests: 21 (45%)
- E2E tests: 8 (17%)
- Priority distribution: P0: 15, P1: 22, P2: 10

**Risk-Based Approach**: This story has a Risk Score of 32/100 (HIGH RISK). Testing focuses heavily on security vulnerabilities (malware scanning, RLS policies, file enumeration), data integrity (backup strategy, OCR validation), and performance (large file handling).

**Reuse Strategy**: Adapting existing `useFileUpload.tsx` hook from PolicyAI codebase with security enhancements and bank-statement-specific logic.

---

## Component Reuse & Migration Plan

### Existing Component: useFileUpload.tsx

**Current Implementation Analysis**:
```typescript
// FROM PolicyAI (existing)
- Uploads to 'sources' bucket
- File path: {notebookId}/{sourceId}.{extension}
- No malware scanning
- No chunked uploads
- Basic error handling
- Uses upsert: false (good - prevents overwrites)
```

**Required Modifications for Bank Statements**:
```typescript
// NEW REQUIREMENTS for Story 2.2
- Upload to 'bank-statements' bucket (NEW)
- File path: {userId}/{uuid}_{sanitized_filename} (SECURITY FIX - no timestamps)
- Add malware scanning pre-upload (CRITICAL - SEC-001)
- Add chunked upload for files > 10MB (CRITICAL - PERF-001)
- Add progress tracking (bytes/total) (REQUIRED - AC2)
- Create backup before processing (CRITICAL - DATA-001)
- Validate file content (not just extension) (CRITICAL - SEC-001)
- Add retry logic with exponential backoff (HIGH - TECH-001)
```

**Migration Strategy**:
1. Create new hook: `useBankStatementUpload.tsx` (extends useFileUpload)
2. Keep original useFileUpload.tsx for sources/receipts
3. Extract shared logic to `src/utils/fileUploadHelpers.ts`
4. Add security layer: `src/utils/fileSecurityValidator.ts`

---

## Test Scenarios by Acceptance Criteria

### AC1: Upload Interface

#### Scenario: 2.2-UNIT-001
- **ID**: 2.2-UNIT-001
- **Level**: Unit
- **Priority**: P1
- **Requirement**: AC1 - Upload interface renders correctly
- **Test**: Verify BankStatementUpload component renders with correct elements
- **Justification**: UI correctness is essential for user experience
- **Given**: User navigates to onboarding step 2
- **When**: Component mounts
- **Then**: 
  - Title displays "Upload Your Bank Statement"
  - Drag-and-drop zone is visible
  - Click-to-browse button exists
  - Continue button is disabled
  - Previa design system colors applied (cream bg, charcoal text)

#### Scenario: 2.2-UNIT-002
- **ID**: 2.2-UNIT-002
- **Level**: Unit
- **Priority**: P0
- **Requirement**: AC1 - File type validation
- **Test**: Validate only .pdf and .csv files are accepted
- **Justification**: Critical input validation to prevent invalid file types
- **Given**: File validation function
- **When**: User selects files with various extensions
- **Then**:
  - `.pdf` file: validation passes
  - `.csv` file: validation passes
  - `.jpg`, `.png`, `.txt`, `.exe`: validation fails with error message
  - `.PDF`, `.CSV` (uppercase): validation passes (case-insensitive)

#### Scenario: 2.2-UNIT-003
- **ID**: 2.2-UNIT-003
- **Level**: Unit
- **Priority**: P0
- **Requirement**: AC1 - File size validation
- **Test**: Validate files <= 50MB accepted, > 50MB rejected
- **Justification**: Prevents system overload and aligns with Supabase limits
- **Given**: File size validation function
- **When**: User selects files of various sizes
- **Then**:
  - 1MB file: validation passes
  - 50MB file: validation passes (boundary)
  - 50.1MB file: validation fails with "File too large (max 50MB)"
  - 100MB file: validation fails

#### Scenario: 2.2-UNIT-004
- **ID**: 2.2-UNIT-004
- **Level**: Unit
- **Priority**: P1
- **Requirement**: AC1 - File preview display
- **Test**: Selected file details displayed correctly
- **Justification**: User feedback for selected file
- **Given**: Valid file selected
- **When**: File state updates
- **Then**:
  - File name displayed
  - File size displayed (formatted: "2.5 MB")
  - File type icon shown (PDF/CSV icon)
  - Continue button becomes enabled

#### Scenario: 2.2-UNIT-005
- **ID**: 2.2-UNIT-005
- **Level**: Unit
- **Priority**: P2
- **Requirement**: AC1 - Drag and drop interaction
- **Test**: Drag and drop zone responds to file drop events
- **Justification**: Enhanced UX for file upload
- **Given**: Component mounted with drag-drop enabled
- **When**: User drags file over zone
- **Then**:
  - Zone highlights with border color change
  - Drop cursor indicates valid drop target
- **When**: User drops valid file
- **Then**: File is selected and preview appears

---

### AC2: File Upload to Supabase Storage

#### Scenario: 2.2-UNIT-006 (NEW - Malware Scanning)
- **ID**: 2.2-UNIT-006
- **Level**: Unit
- **Priority**: P0 ⚠️ CRITICAL - SEC-001
- **Requirement**: AC2 - Malware scanning before upload
- **Test**: Validate file content before upload (not just extension)
- **Justification**: CRITICAL security risk - malicious files could compromise system
- **Given**: File selected for upload
- **When**: Pre-upload security validation runs
- **Then**:
  - File MIME type validated (actual content, not just extension)
  - PDF: MIME type must be `application/pdf`
  - CSV: MIME type must be `text/csv` or `text/plain`
  - `.pdf.exe` renamed to `.pdf`: MIME validation fails
  - File with embedded scripts: validation flags suspicious content
- **Mock**: ClamAV scanner integration (mock for unit test)

#### Scenario: 2.2-INT-001 (NEW - Malware Integration)
- **ID**: 2.2-INT-001
- **Level**: Integration
- **Priority**: P0 ⚠️ CRITICAL - SEC-001
- **Requirement**: AC2 - ClamAV malware scanning integration
- **Test**: Actual malware scanning with ClamAV (or similar)
- **Justification**: CRITICAL - validates malware detection works end-to-end
- **Given**: ClamAV scanner configured and running
- **When**: User uploads test malware file (EICAR test file)
- **Then**:
  - Upload blocked with error: "File contains malware and cannot be uploaded"
  - File never reaches Supabase Storage
  - Error logged with malware signature details
  - User shown clear error message with support contact

#### Scenario: 2.2-UNIT-007 (UPDATED - UUID File Paths)
- **ID**: 2.2-UNIT-007
- **Level**: Unit
- **Priority**: P0 ⚠️ CRITICAL - SEC-003
- **Requirement**: AC2 - Non-predictable file path generation
- **Test**: File paths use UUIDs instead of timestamps
- **Justification**: CRITICAL - prevents file enumeration attacks
- **Given**: uploadBankStatement function called
- **When**: File path is generated
- **Then**:
  - Format: `{userId}/{uuid}_{sanitized_filename}`
  - UUID is v4 random (not timestamp-based)
  - Filename sanitized (spaces→underscores, special chars removed)
  - Example: `user123/a1b2c3d4-e5f6-7890-abcd-ef1234567890_statement_nov_2024.pdf`
- **Security**: Verify paths are not guessable via timestamp enumeration

#### Scenario: 2.2-UNIT-008 (NEW - Filename Sanitization)
- **ID**: 2.2-UNIT-008
- **Level**: Unit
- **Priority**: P0
- **Requirement**: AC2 - Filename sanitization prevents path traversal
- **Test**: Malicious filenames are sanitized
- **Justification**: Prevents directory traversal attacks
- **Given**: Files with malicious names
- **When**: Filename sanitization runs
- **Then**:
  - `../../../etc/passwd.pdf` → `etc_passwd.pdf`
  - `<script>alert(1)</script>.pdf` → `scriptalert1script.pdf`
  - `file name with spaces.csv` → `file_name_with_spaces.csv`
  - `file|name?.pdf` → `filename.pdf`

#### Scenario: 2.2-INT-002
- **ID**: 2.2-INT-002
- **Level**: Integration
- **Priority**: P0
- **Requirement**: AC2 - File upload to Supabase Storage
- **Test**: Valid file uploads successfully to bank-statements bucket
- **Justification**: Core functionality - file must reach storage
- **Given**: Valid 2MB PDF file, authenticated user
- **When**: uploadBankStatement() called
- **Then**:
  - File uploaded to Supabase Storage `bank-statements` bucket
  - File path returned: `{userId}/{uuid}_{filename}`
  - File accessible via signed URL (1 hour expiry)
  - File metadata stored (size, mime type, upload timestamp)

#### Scenario: 2.2-INT-003 (NEW - Chunked Upload)
- **ID**: 2.2-INT-003
- **Level**: Integration
- **Priority**: P0 ⚠️ CRITICAL - PERF-001
- **Requirement**: AC2 - Chunked upload for files > 10MB
- **Test**: Large files uploaded in chunks with resumability
- **Justification**: CRITICAL - prevents UI blocking and supports resume
- **Given**: 50MB PDF file (max size), slow connection (1 Mbps simulated)
- **When**: Upload initiated
- **Then**:
  - File split into 5MB chunks (10 chunks total)
  - Each chunk uploaded sequentially with progress tracking
  - Progress callback fires: 10%, 20%, ..., 100%
  - Total upload time < 5 minutes (50MB ÷ 1Mbps ≈ 400 seconds)
  - If network interruption occurs, upload resumes from last completed chunk

#### Scenario: 2.2-INT-004 (NEW - Upload Resume)
- **ID**: 2.2-INT-004
- **Level**: Integration
- **Priority**: P1
- **Requirement**: AC2 - Upload resume after network failure
- **Test**: Upload continues from last chunk after interruption
- **Justification**: User experience - don't lose progress on network issues
- **Given**: 30MB file uploading (60% complete, 18MB uploaded)
- **When**: Network disconnects for 10 seconds, then reconnects
- **Then**:
  - Upload pauses with status "Connection lost, retrying..."
  - On reconnect, upload resumes from chunk 7 (after 18MB)
  - Remaining chunks upload successfully
  - User sees continuous progress (doesn't restart from 0%)

#### Scenario: 2.2-UNIT-009
- **ID**: 2.2-UNIT-009
- **Level**: Unit
- **Priority**: P1
- **Requirement**: AC2 - Upload progress tracking
- **Test**: Progress callback provides accurate percentage
- **Justification**: User feedback during long uploads
- **Given**: Mock upload with progress events
- **When**: Upload progresses through chunks
- **Then**:
  - Progress callback receives values: 0, 10, 20, ..., 100
  - UI progress bar updates smoothly
  - Percentage matches actual bytes uploaded
  - Formula: (uploaded_bytes / total_bytes) × 100

#### Scenario: 2.2-INT-005
- **ID**: 2.2-INT-005
- **Level**: Integration
- **Priority**: P0
- **Requirement**: AC2 - Network error handling
- **Test**: Upload failure handled gracefully
- **Justification**: Resilience - network issues are common
- **Given**: Network failure simulated during upload
- **When**: Upload attempt fails
- **Then**:
  - Error caught and logged
  - User sees toast: "Upload failed due to network error. Retry?"
  - Retry button available
  - On retry, upload resumes (not restart)

#### Scenario: 2.2-INT-006
- **ID**: 2.2-INT-006
- **Level**: Integration
- **Priority**: P1
- **Requirement**: AC2 - Storage quota exceeded
- **Test**: Graceful handling when user hits storage limit
- **Justification**: Business logic - prevent poor UX on quota limit
- **Given**: User at 95% of storage quota, uploads 10MB file (exceeds limit)
- **When**: Upload attempted
- **Then**:
  - Pre-upload quota check detects insufficient space
  - Upload blocked before file transfer
  - Error message: "Storage limit reached (48.5/50 MB used). Please contact support or delete old files."
  - User shown storage usage dashboard link

---

### AC3: Database Record Creation

#### Scenario: 2.2-INT-007
- **ID**: 2.2-INT-007
- **Level**: Integration
- **Priority**: P0
- **Requirement**: AC3 - bank_statements record created
- **Test**: Database row inserted after successful upload
- **Justification**: Core data flow - record must exist for processing
- **Given**: File uploaded successfully to storage
- **When**: createBankStatementRecord() called
- **Then**:
  - Row inserted in `bank_statements` table
  - Fields populated:
    - `id`: UUID generated
    - `user_id`: Current authenticated user
    - `file_path`: Storage path returned from upload
    - `file_size`: File size in bytes
    - `processing_status`: 'pending'
    - `created_at`: Current timestamp
  - UUID returned for subsequent operations

#### Scenario: 2.2-INT-008 (NEW - RLS Policy Validation)
- **ID**: 2.2-INT-008
- **Level**: Integration
- **Priority**: P0 ⚠️ CRITICAL - SEC-002
- **Requirement**: AC3 - RLS prevents cross-user data access
- **Test**: User B cannot access User A's bank statement record
- **Justification**: CRITICAL - financial data must be isolated per user
- **Given**: User A uploads statement (record ID: `stmt-a-123`)
- **When**: User B attempts to query bank_statements table
- **Then**:
  - User B's query returns 0 results (filtered by RLS)
  - Direct API call with stmt-a-123 returns 403 Forbidden
  - Supabase client respects RLS: `where('user_id', 'eq', userB.id)` returns empty
  - RLS policy: `USING (auth.uid() = user_id)`

#### Scenario: 2.2-INT-009 (NEW - RLS with Expired Token)
- **ID**: 2.2-INT-009
- **Level**: Integration
- **Priority**: P0 ⚠️ CRITICAL - SEC-002
- **Requirement**: AC3 - RLS blocks access with expired JWT
- **Test**: Expired or invalid JWT cannot access records
- **Justification**: CRITICAL - prevents unauthorized access via token manipulation
- **Given**: User A has valid record `stmt-a-123`
- **When**: Request made with expired JWT token
- **Then**:
  - Query returns 401 Unauthorized (not 403)
  - No data leaked in error message
  - Auth middleware blocks before RLS check

#### Scenario: 2.2-INT-010
- **ID**: 2.2-INT-010
- **Level**: Integration
- **Priority**: P1
- **Requirement**: AC3 - Database insert error handling
- **Test**: Handle database constraints and errors
- **Justification**: Resilience - database issues shouldn't crash app
- **Given**: Database temporarily unavailable or constraint violation
- **When**: Insert attempted
- **Then**:
  - Error caught with specific error type
  - User sees: "Failed to create record. Please retry."
  - Error logged with context: user_id, file_path, error details
  - File remains in storage (can be retried)
  - Orphaned files cleaned up after 24 hours (separate cleanup job)

---

### AC4: Trigger OCR Processing

#### Scenario: 2.2-INT-011
- **ID**: 2.2-INT-011
- **Level**: Integration
- **Priority**: P0
- **Requirement**: AC4 - Edge Function called successfully
- **Test**: process-document Edge Function invoked with correct payload
- **Justification**: Core integration - triggers OCR workflow
- **Given**: bank_statement record created (ID: `stmt-123`)
- **When**: triggerBankStatementProcessing() called
- **Then**:
  - Edge Function `process-document` invoked
  - Payload includes:
    - `document_id`: 'stmt-123'
    - `user_id`: authenticated user UUID
    - `document_type`: 'bank_statement'
    - `file_path`: storage path
    - `storage_bucket`: 'bank-statements'
  - Response: 202 Accepted
  - Status in database updates to 'processing'

#### Scenario: 2.2-INT-012 (NEW - n8n Circuit Breaker)
- **ID**: 2.2-INT-012
- **Level**: Integration
- **Priority**: P0 ⚠️ CRITICAL - TECH-001
- **Requirement**: AC4 - Circuit breaker prevents cascading n8n failures
- **Test**: After 5 consecutive n8n failures, circuit opens
- **Justification**: CRITICAL - prevents system overload when n8n is down
- **Given**: n8n service is down (simulated)
- **When**: 5 consecutive Edge Function calls fail (5xx errors)
- **Then**:
  - Circuit breaker opens after 5th failure
  - 6th call fails immediately without attempting n8n: "Processing service temporarily unavailable"
  - Status set to 'failed' with reason: "Service unavailable"
  - Manual processing queue entry created
  - Circuit closes after 5 minutes or manual intervention

#### Scenario: 2.2-INT-013 (NEW - Retry with Exponential Backoff)
- **ID**: 2.2-INT-013
- **Level**: Integration
- **Priority**: P1 ⚠️ HIGH - TECH-001
- **Requirement**: AC4 - Retry logic for transient n8n failures
- **Test**: Edge Function retries on transient failures
- **Justification**: HIGH - improves reliability for temporary issues
- **Given**: n8n returns 503 Service Unavailable (transient)
- **When**: Edge Function call fails
- **Then**:
  - Retry 1: After 2 seconds
  - Retry 2: After 4 seconds (exponential)
  - Retry 3: After 8 seconds (exponential)
  - Max 3 retries over ~14 seconds
  - If all retries fail: Status = 'failed', trigger manual queue
  - If retry succeeds: Status = 'processing', continue normally

#### Scenario: 2.2-INT-014
- **ID**: 2.2-INT-014
- **Level**: Integration
- **Priority**: P1
- **Requirement**: AC4 - Edge Function timeout handling
- **Test**: Long-running Edge Function calls timeout gracefully
- **Justification**: Prevents hung requests blocking user
- **Given**: Edge Function call takes > 30 seconds (timeout threshold)
- **When**: Timeout occurs
- **Then**:
  - Request cancelled with timeout error
  - User sees: "Processing is taking longer than expected. Your upload is saved and will be processed in the background."
  - Status remains 'pending' (retry later via cron job)
  - Background worker picks up pending items after 5 minutes

#### Scenario: 2.2-INT-015
- **ID**: 2.2-INT-015
- **Level**: Integration
- **Priority**: P2
- **Requirement**: AC4 - n8n webhook payload validation
- **Test**: Edge Function validates response from n8n
- **Justification**: Data integrity - ensure n8n confirms receipt
- **Given**: Edge Function calls n8n webhook
- **When**: n8n responds
- **Then**:
  - 202 Accepted: Processing started successfully
  - 400 Bad Request: Validation error logged, status = 'failed'
  - 500 Internal Server Error: Trigger retry logic
  - Response payload validated (JSON schema check)

---

### AC5: Processing Status Display

#### Scenario: 2.2-INT-016
- **ID**: 2.2-INT-016
- **Level**: Integration
- **Priority**: P0
- **Requirement**: AC5 - Status polling with React Query
- **Test**: Processing status polled every 2 seconds until terminal state
- **Justification**: Core UX - user needs real-time status feedback
- **Given**: bank_statement record with status 'processing'
- **When**: useProcessingStatus hook mounted
- **Then**:
  - React Query polls database every 2 seconds
  - Query: `SELECT processing_status FROM bank_statements WHERE id = ? AND user_id = ?`
  - Polling continues while status is 'pending' or 'processing'
  - Polling stops when status is 'completed' or 'failed'
  - RLS policy enforced on polling queries

#### Scenario: 2.2-UNIT-010
- **ID**: 2.2-UNIT-010
- **Level**: Unit
- **Priority**: P1
- **Requirement**: AC5 - Processing status UI states
- **Test**: UI displays correct message per status
- **Justification**: User communication clarity
- **Given**: ProcessingStatus component rendered
- **When**: Status changes
- **Then**:
  - 'pending': "Preparing your statement for processing..."
  - 'processing': "Processing your statement... This usually takes 5-10 seconds"
  - 'completed': Redirect to confirmation screen
  - 'failed': "Processing failed. Please try again." + Retry button

#### Scenario: 2.2-UNIT-011 (NEW - Exponential Backoff Polling)
- **ID**: 2.2-UNIT-011
- **Level**: Unit
- **Priority**: P2 ⚠️ MEDIUM - PERF-003
- **Requirement**: AC5 - Polling uses exponential backoff
- **Test**: Polling interval increases to reduce database load
- **Justification**: MEDIUM - reduces unnecessary database queries
- **Given**: Processing takes longer than expected
- **When**: Status remains 'processing' for > 20 seconds
- **Then**:
  - Initial interval: 2s (0-10s)
  - After 10s: Increase to 4s (10-20s)
  - After 20s: Increase to 8s (20-40s)
  - After 40s: Increase to 16s (40s+)
  - Max interval: 16s
  - If status is still 'processing' after 5 minutes: Show "Taking longer than usual" message

#### Scenario: 2.2-INT-017
- **ID**: 2.2-INT-017
- **Level**: Integration
- **Priority**: P1
- **Requirement**: AC5 - Redirect on completion
- **Test**: User redirected to confirmation screen after completion
- **Justification**: User flow continuation
- **Given**: Status changes from 'processing' to 'completed'
- **When**: React Query detects status change
- **Then**:
  - useNavigate('/onboarding/confirm-account') called
  - User sees account confirmation screen (Story 2.3)
  - Processing UI unmounts cleanly

#### Scenario: 2.2-INT-018
- **ID**: 2.2-INT-018
- **Level**: Integration
- **Priority**: P1
- **Requirement**: AC5 - Retry functionality on failure
- **Test**: User can retry after processing failure
- **Justification**: Recovery path for users
- **Given**: Status is 'failed'
- **When**: User clicks "Retry" button
- **Then**:
  - triggerBankStatementProcessing() called again
  - Status updated to 'pending'
  - Polling resumes
  - Original file remains in storage (no re-upload needed)

#### Scenario: 2.2-INT-019
- **ID**: 2.2-INT-019
- **Level**: Integration
- **Priority**: P2
- **Requirement**: AC5 - Network error handling during polling
- **Test**: Polling continues despite network interruptions
- **Justification**: Resilience - user shouldn't lose progress on network blip
- **Given**: Status polling active
- **When**: Network disconnects briefly during poll
- **Then**:
  - React Query retry logic engages (3 retries)
  - UI shows: "Connection lost, retrying..."
  - Polling resumes when network returns
  - User sees seamless continuation (no error modal)

---

### AC6: Gamification Points

#### Scenario: 2.2-INT-020 (UPDATED - Retry Queue)
- **ID**: 2.2-INT-020
- **Level**: Integration
- **Priority**: P0 ⚠️ HIGH - OPS-002
- **Requirement**: AC6 - Gamification points awarded with retry queue
- **Test**: Points awarded even if initial attempt fails
- **Justification**: HIGH - users must receive earned rewards
- **Given**: File uploaded successfully
- **When**: awardPoints(5, 'First bank statement uploaded') called
- **Then**:
  - Successful case:
    - Row inserted in `point_transactions` table
    - `total_points` in `gamification_profiles` incremented by 5
    - No user notification (backend only per AC6)
  - Failure case (gamification_profiles unavailable):
    - Error logged: "Gamification award failed for user {userId}"
    - Record added to `gamification_retry_queue` table
    - Background worker retries after 5 minutes
    - User notified if retry fails 3 times: "We couldn't award your points. Contact support."

#### Scenario: 2.2-INT-021 (NEW - Retry Queue Background Worker)
- **ID**: 2.2-INT-021
- **Level**: Integration
- **Priority**: P1 ⚠️ HIGH - OPS-002
- **Requirement**: AC6 - Background worker processes retry queue
- **Test**: Failed gamification awards retried successfully
- **Justification**: HIGH - ensures users eventually receive points
- **Given**: 3 failed point awards in retry queue
- **When**: Background worker runs (every 5 minutes)
- **Then**:
  - Worker fetches pending items from `gamification_retry_queue`
  - Retries each award in order
  - Successful awards: Remove from queue, mark as completed
  - Failed awards: Increment retry_count, reschedule for next run
  - After 3 failed retries: Send user notification + admin alert

#### Scenario: 2.2-UNIT-012
- **ID**: 2.2-UNIT-012
- **Level**: Unit
- **Priority**: P1
- **Requirement**: AC6 - Gamification failure doesn't block upload
- **Test**: Upload succeeds even if gamification fails
- **Justification**: Upload is more critical than points
- **Given**: Gamification service throws error
- **When**: Upload flow continues
- **Then**:
  - Upload completes successfully
  - User redirected to next step
  - Error logged but not shown to user
  - Points awarded later via retry queue

---

## Security Test Scenarios

### Scenario: 2.2-SEC-001 (NEW - File Enumeration Attack)
- **ID**: 2.2-SEC-001
- **Level**: Integration
- **Priority**: P0 ⚠️ CRITICAL - SEC-003
- **Requirement**: Security - Prevent file path enumeration
- **Test**: Attacker cannot enumerate files by guessing paths
- **Justification**: CRITICAL - prevents unauthorized access to financial data
- **Given**: User A uploads file at path: `userA/uuid123_statement.pdf`
- **When**: Attacker (User B) attempts enumeration:
  - Try sequential UUIDs
  - Try predictable patterns
  - Try timestamp-based guessing
- **Then**:
  - All attempts return 403 Forbidden (not 404 to avoid leaking existence)
  - Signed URLs required for all access (1 hour expiry)
  - RLS policy blocks unauthorized access
  - Audit log records suspicious access patterns

### Scenario: 2.2-SEC-002 (NEW - Signed URL Expiry)
- **ID**: 2.2-SEC-002
- **Level**: Integration
- **Priority**: P0 ⚠️ CRITICAL - SEC-003
- **Requirement**: Security - Signed URLs expire after 1 hour
- **Test**: Expired signed URLs cannot access files
- **Justification**: CRITICAL - prevents persistent unauthorized access
- **Given**: Signed URL generated at T0 with 1 hour expiry
- **When**: Access attempted at T0 + 61 minutes
- **Then**:
  - Request returns 403 Forbidden
  - Error: "Signed URL expired"
  - User must request new signed URL
  - n8n webhook must regenerate signed URL if processing delayed

### Scenario: 2.2-SEC-003 (NEW - Rate Limiting)
- **ID**: 2.2-SEC-003
- **Level**: Integration
- **Priority**: P1
- **Requirement**: Security - Rate limit uploads per user
- **Test**: User cannot upload more than 10 files per hour
- **Justification**: Prevents abuse and DoS attacks
- **Given**: User has uploaded 10 files in past hour
- **When**: 11th upload attempted
- **Then**:
  - Upload blocked before file transfer
  - Error: "Upload limit reached (10/hour). Please try again in {minutes} minutes."
  - Rate limit resets hourly (sliding window)
  - Admin users exempt from rate limit

### Scenario: 2.2-SEC-004 (NEW - File Content Validation)
- **ID**: 2.2-SEC-004
- **Level**: Unit
- **Priority**: P0 ⚠️ CRITICAL - SEC-001
- **Requirement**: Security - Validate file content matches declared type
- **Test**: File with fake extension detected
- **Justification**: CRITICAL - prevents executable files disguised as PDFs
- **Given**: `.exe` file renamed to `.pdf`
- **When**: File content validation runs
- **Then**:
  - MIME type check fails (actual: `application/x-msdownload`, expected: `application/pdf`)
  - Upload blocked with error: "File type mismatch detected"
  - File never reaches storage
  - Security event logged

---

## Data Integrity Test Scenarios

### Scenario: 2.2-DATA-001 (NEW - Backup Creation)
- **ID**: 2.2-DATA-001
- **Level**: Integration
- **Priority**: P0 ⚠️ CRITICAL - DATA-001
- **Requirement**: Data - Backup created before processing
- **Test**: Original file backed up before OCR processing
- **Justification**: CRITICAL - prevents data loss if processing corrupts file
- **Given**: File uploaded to `bank-statements/{userId}/{uuid}_statement.pdf`
- **When**: Before triggering OCR processing
- **Then**:
  - Backup copy created at `bank-statements/{userId}/backups/{uuid}_statement.pdf`
  - Both original and backup exist in storage
  - Backup metadata stored in database
  - Retention policy: 7 years (Australian financial document requirement)

### Scenario: 2.2-DATA-002 (NEW - Backup Restoration)
- **ID**: 2.2-DATA-002
- **Level**: Integration
- **Priority**: P0 ⚠️ CRITICAL - DATA-001
- **Requirement**: Data - Restore from backup after corruption
- **Test**: Corrupted file can be restored from backup
- **Justification**: CRITICAL - validates backup recovery process works
- **Given**: Original file corrupted during processing (simulated)
- **When**: User requests file download or reprocessing
- **Then**:
  - System detects corruption (file size = 0 or checksum mismatch)
  - Backup automatically restored to original location
  - User notified: "Original file was corrupted. We've restored it from backup."
  - Reprocessing triggered with restored file

### Scenario: 2.2-DATA-003 (NEW - OCR Data Validation)
- **ID**: 2.2-DATA-003
- **Level**: Integration
- **Priority**: P0 ⚠️ HIGH - DATA-002
- **Requirement**: Data - Validate OCR extraction quality
- **Test**: Low-quality OCR extractions flagged for review
- **Justification**: HIGH - prevents users seeing garbage data
- **Given**: OCR completes with extraction_confidence = 0.65 (below 0.90 threshold)
- **When**: OCR results received
- **Then**:
  - Status set to 'completed_with_errors' (not 'completed')
  - Manual review queue entry created
  - User sees: "We extracted your data, but some fields need verification"
  - Low-confidence fields highlighted in yellow
  - User can confirm or correct data

---

## Performance Test Scenarios

### Scenario: 2.2-PERF-001 (NEW - Large File Upload Performance)
- **ID**: 2.2-PERF-001
- **Level**: Integration
- **Priority**: P0 ⚠️ CRITICAL - PERF-001
- **Requirement**: Performance - 50MB file uploads within 5 minutes
- **Test**: Maximum size file uploads successfully on slow connection
- **Justification**: CRITICAL - users on slow connections must be supported
- **Given**: 50MB PDF file, 1 Mbps connection (simulated via throttling)
- **When**: Upload initiated
- **Then**:
  - Chunked upload (5MB chunks = 10 chunks)
  - Progress updates every chunk (10%, 20%, ..., 100%)
  - Total time: ~400 seconds (50MB ÷ 1Mbps theoretical = 400s)
  - Actual time with overhead: < 500 seconds (8 minutes with retries)
  - UI remains responsive throughout
  - User can navigate away (background upload)

### Scenario: 2.2-PERF-002 (NEW - Concurrent Upload Load Test)
- **ID**: 2.2-PERF-002
- **Level**: Integration
- **Priority**: P1
- **Requirement**: Performance - Handle 100 concurrent uploads
- **Test**: System handles high load without degradation
- **Justification**: Scalability validation
- **Given**: 100 users simultaneously uploading 10MB files
- **When**: Load test runs for 5 minutes
- **Then**:
  - All uploads complete successfully
  - Average upload time: < 2 minutes per file
  - No database connection pool exhaustion
  - Supabase Storage doesn't throttle requests
  - Edge Function concurrency handled (max 50 concurrent)

### Scenario: 2.2-PERF-003 (NEW - Polling Efficiency)
- **ID**: 2.2-PERF-003
- **Level**: Integration
- **Priority**: P2 ⚠️ MEDIUM - PERF-003
- **Requirement**: Performance - Polling doesn't overload database
- **Test**: 1000 concurrent polling requests handled efficiently
- **Justification**: MEDIUM - prevents database bottleneck
- **Given**: 1000 users with active status polling
- **When**: All poll simultaneously (worst case)
- **Then**:
  - Database handles 500 queries/second (2s interval)
  - Index on (user_id, processing_status) used
  - Query execution time: < 10ms per query
  - No connection pool exhaustion
  - Exponential backoff reduces load after 20s

---

## E2E Test Scenarios

### Scenario: 2.2-E2E-001
- **ID**: 2.2-E2E-001
- **Level**: E2E
- **Priority**: P0
- **Requirement**: Complete happy path flow
- **Test**: User uploads bank statement and sees completion
- **Justification**: Critical user journey validation
- **Given**: User authenticated and on onboarding step 2
- **When**: User completes entire flow
- **Then**:
  1. Drag-drop 5MB PDF file
  2. File preview appears
  3. Click "Continue"
  4. Upload progress bar shows 0-100%
  5. Processing status displays
  6. After 5-10 seconds, status = 'completed'
  7. Redirect to confirmation screen
  8. 5 gamification points awarded (backend)

### Scenario: 2.2-E2E-002
- **ID**: 2.2-E2E-002
- **Level**: E2E
- **Priority**: P1
- **Requirement**: Error handling - invalid file type
- **Test**: User attempts to upload unsupported file
- **Justification**: Common user error path
- **Given**: User on upload screen
- **When**: User selects `.jpg` image file
- **Then**:
  1. File rejected immediately
  2. Error message: "Invalid file type. Please upload a PDF or CSV file."
  3. Upload interface remains active
  4. User can select different file

### Scenario: 2.2-E2E-003 (NEW - Malware Detection)
- **ID**: 2.2-E2E-003
- **Level**: E2E
- **Priority**: P0 ⚠️ CRITICAL - SEC-001
- **Requirement**: Security - Malware blocked end-to-end
- **Test**: Malicious file blocked at every stage
- **Justification**: CRITICAL - validates security layer works in production-like environment
- **Given**: User attempts to upload EICAR test file (standard malware test)
- **When**: Upload initiated
- **Then**:
  1. File selected successfully
  2. Pre-upload scan detects malware
  3. Upload blocked with clear error: "This file contains malware and cannot be uploaded. Please scan your device with antivirus software."
  4. File never reaches Supabase Storage
  5. Security event logged with details
  6. User can select different file

### Scenario: 2.2-E2E-004 (NEW - Large File Upload)
- **ID**: 2.2-E2E-004
- **Level**: E2E
- **Priority**: P0 ⚠️ CRITICAL - PERF-001
- **Requirement**: Performance - Large file uploads smoothly
- **Test**: 50MB file uploads with good UX
- **Justification**: CRITICAL - validates chunked upload UX
- **Given**: User has 50MB PDF bank statement
- **When**: User uploads file
- **Then**:
  1. File validation passes (50MB = max allowed)
  2. Upload starts immediately (no delay)
  3. Progress bar shows smooth progression
  4. Time remaining estimate displayed: "~6 minutes remaining"
  5. User can navigate away (upload continues in background)
  6. Toast notification on completion: "Bank statement uploaded successfully"

### Scenario: 2.2-E2E-005 (NEW - Network Interruption Recovery)
- **ID**: 2.2-E2E-005
- **Level**: E2E
- **Priority**: P1
- **Requirement**: Resilience - Upload resumes after network issue
- **Test**: User experiences network drop mid-upload
- **Justification**: Real-world scenario validation
- **Given**: User uploading 30MB file (60% complete)
- **When**: Network disconnects for 15 seconds (simulated)
- **Then**:
  1. Upload pauses
  2. UI shows: "Connection lost. Retrying..."
  3. Network reconnects
  4. Upload resumes from 60%
  5. Remaining 40% uploads successfully
  6. No user action required

### Scenario: 2.2-E2E-006
- **ID**: 2.2-E2E-006
- **Level**: E2E
- **Priority**: P1
- **Requirement**: Processing failure with retry
- **Test**: User retries after processing failure
- **Justification**: Recovery path validation
- **Given**: Processing fails (n8n down, simulated)
- **When**: Status shows 'failed'
- **Then**:
  1. Error message: "Processing failed. This could be a temporary issue."
  2. "Retry" button visible
  3. User clicks Retry
  4. Processing resumes (n8n now available)
  5. Status changes to 'processing' → 'completed'
  6. User redirected to confirmation

### Scenario: 2.2-E2E-007 (NEW - Cross-User Isolation)
- **ID**: 2.2-E2E-007
- **Level**: E2E
- **Priority**: P0 ⚠️ CRITICAL - SEC-002
- **Requirement**: Security - Users cannot see others' files
- **Test**: Complete isolation between users
- **Justification**: CRITICAL - financial data privacy
- **Given**: User A uploaded statement (ID: stmt-a-123)
- **When**: User B logs in and views their dashboard
- **Then**:
  1. User B sees only their own uploads (0 files)
  2. Attempting direct URL to User A's file: 403 Forbidden
  3. API calls filtered by RLS: User B gets empty array
  4. Storage bucket access blocked by RLS
  5. No data leakage in error messages or logs

### Scenario: 2.2-E2E-008 (NEW - Gamification Integration)
- **ID**: 2.2-E2E-008
- **Level**: E2E
- **Priority**: P1
- **Requirement**: Gamification - Points awarded for first upload
- **Test**: User earns 5 points on first bank statement upload
- **Justification**: Feature integration validation
- **Given**: User completes their first bank statement upload
- **When**: Upload and processing complete
- **Then**:
  1. Upload succeeds
  2. Backend awards 5 points (no UI notification per AC6)
  3. Query gamification_profiles: total_points = 5
  4. Query point_transactions: 1 row with reason "First bank statement uploaded"
  5. If gamification fails: Retry queue captures for later processing

---

## Test Execution Priority

### P0 Tests (Must Pass - Blocking Issues)
- Total: 15 scenarios
- Security: 5 (SEC-001, SEC-002, SEC-003, SEC-004, E2E-003, E2E-007)
- Data Integrity: 3 (DATA-001, DATA-002, DATA-003)
- Performance: 2 (PERF-001, E2E-004)
- Core Functionality: 5 (INT-002, INT-007, INT-011, INT-016, E2E-001)

**Execution Order**:
1. Run all security tests first (SEC-001 through SEC-004)
2. Run data integrity tests (DATA-001 through DATA-003)
3. Run core integration tests (INT-002, INT-007, INT-011, INT-016)
4. Run E2E happy path (E2E-001)
5. Run E2E security validation (E2E-003, E2E-007)

### P1 Tests (Should Pass - Important Quality)
- Total: 22 scenarios
- Complete within sprint

### P2 Tests (Nice to Have - Enhancements)
- Total: 10 scenarios
- Can be deferred if time constrained

---

## Test Environment Setup

### Prerequisites
- Supabase project: https://clfdfkkyurghuohjnryy.supabase.co
- Test user accounts: userA@test.com, userB@test.com
- ClamAV scanner installed and running (for SEC-001 tests)
- Network throttling tools (for PERF-001 tests)
- Test files:
  - Valid: `test-bank-statement-5mb.pdf`, `test-statement.csv`
  - Invalid: `test-image.jpg`, `test-executable.exe`
  - Malware: `eicar-test-file.pdf` (EICAR standard test)
  - Large: `test-statement-50mb.pdf`

### Test Data Setup
```sql
-- Create test users in auth.users
-- Create test gamification_profiles
-- Create test bank_accounts (if needed)
```

### Mocks Required
- ClamAV scanner (for unit tests)
- n8n webhook (for Edge Function tests)
- Network conditions (throttling for performance tests)

---

## Coverage Targets

- **Unit Test Coverage**: 80% (18 scenarios covering core logic)
- **Integration Test Coverage**: 90% (21 scenarios covering API interactions)
- **E2E Test Coverage**: 100% of critical paths (8 scenarios)

**Focus Areas** (High Risk - Low Coverage Gap):
1. Security validation (malware, RLS, file paths)
2. Data integrity (backups, OCR validation)
3. Performance (chunked uploads, polling)
4. Error handling (retry logic, circuit breaker)

---

## Risk Mitigation Through Testing

### Critical Risks Addressed

| Risk ID | Test Scenarios | Mitigation Level |
|---------|----------------|------------------|
| SEC-001 | UNIT-006, INT-001, SEC-004, E2E-003 | High |
| SEC-002 | INT-008, INT-009, E2E-007 | High |
| SEC-003 | UNIT-007, SEC-001, SEC-002 | High |
| DATA-001 | DATA-001, DATA-002 | High |
| DATA-002 | DATA-003 | Medium |
| PERF-001 | INT-003, INT-004, PERF-001, E2E-004, E2E-005 | High |
| TECH-001 | INT-012, INT-013 | High |
| OPS-002 | INT-020, INT-021 | High |

---

## Component Implementation Guidance

### New Hook: useBankStatementUpload.tsx

```typescript
// src/hooks/useBankStatementUpload.tsx
import { useState } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { useToast } from '@/hooks/use-toast';
import { validateFileContent, sanitizeFilename } from '@/utils/fileSecurityValidator';
import { v4 as uuidv4 } from 'uuid';

export const useBankStatementUpload = () => {
  const [isUploading, setIsUploading] = useState(false);
  const [uploadProgress, setUploadProgress] = useState(0);
  const { toast } = useToast();

  const uploadBankStatement = async (
    file: File,
    userId: string
  ): Promise<{ filePath: string; bankStatementId: string } | null> => {
    try {
      setIsUploading(true);
      setUploadProgress(0);

      // CRITICAL: SEC-001 - Validate file content (not just extension)
      const contentValidation = await validateFileContent(file);
      if (!contentValidation.isValid) {
        throw new Error(contentValidation.error);
      }

      // CRITICAL: SEC-003 - Use UUID instead of timestamp
      const uuid = uuidv4();
      const sanitizedFilename = sanitizeFilename(file.name);
      const filePath = `${userId}/${uuid}_${sanitizedFilename}`;

      // Chunked upload for files > 10MB (CRITICAL: PERF-001)
      if (file.size > 10 * 1024 * 1024) {
        return await uploadInChunks(file, filePath, setUploadProgress);
      }

      // Standard upload for smaller files
      const { data, error } = await supabase.storage
        .from('bank-statements')
        .upload(filePath, file, {
          cacheControl: '3600',
          upsert: false, // Prevent overwrites
          onUploadProgress: (progress) => {
            const percent = (progress.loaded / progress.total) * 100;
            setUploadProgress(percent);
          }
        });

      if (error) throw error;

      // CRITICAL: DATA-001 - Create backup before processing
      await createBackup(filePath, file);

      // Create database record (AC3)
      const bankStatementId = await createBankStatementRecord(
        userId,
        data.path,
        file.size
      );

      return { filePath: data.path, bankStatementId };
    } catch (error) {
      console.error('Bank statement upload failed:', error);
      toast({
        title: "Upload Error",
        description: error.message,
        variant: "destructive",
      });
      return null;
    } finally {
      setIsUploading(false);
    }
  };

  return {
    uploadBankStatement,
    isUploading,
    uploadProgress,
  };
};
```

### File Security Validator

```typescript
// src/utils/fileSecurityValidator.ts

export async function validateFileContent(file: File): Promise<{isValid: boolean, error?: string}> {
  // Check MIME type matches extension
  const actualMimeType = file.type;
  const expectedMimeTypes = {
    'pdf': ['application/pdf'],
    'csv': ['text/csv', 'text/plain']
  };
  
  const extension = file.name.split('.').pop()?.toLowerCase();
  if (!extension || !expectedMimeTypes[extension]) {
    return { isValid: false, error: 'Unsupported file type' };
  }

  if (!expectedMimeTypes[extension].includes(actualMimeType)) {
    return { 
      isValid: false, 
      error: 'File type mismatch detected. Please ensure your file is a valid PDF or CSV.' 
    };
  }

  // TODO: Integrate ClamAV scanning here (CRITICAL: SEC-001)
  // For MVP, we're validating MIME type. Full malware scanning required before production.
  
  return { isValid: true };
}

export function sanitizeFilename(filename: string): string {
  return filename
    .replace(/[^a-zA-Z0-9._-]/g, '_') // Replace special chars with underscore
    .replace(/_{2,}/g, '_') // Replace multiple underscores with single
    .toLowerCase();
}
```

---

## Test Execution Checklist

Before marking story as "Ready for Review":

- [ ] All P0 tests executed and passing
- [ ] Security tests validated (malware scanning, RLS, file enumeration)
- [ ] Data integrity tests passed (backup, restoration, OCR validation)
- [ ] Performance tests passed (50MB upload < 5 min, 100 concurrent users)
- [ ] Integration tests with actual Supabase instance passed
- [ ] E2E tests passed on staging environment
- [ ] Cross-browser testing completed (Chrome, Firefox, Safari)
- [ ] Mobile responsiveness verified
- [ ] Test coverage report generated (>80% unit, >90% integration)
- [ ] All critical risks (Score 9) have corresponding passing tests

---

## Monitoring & Observability

**Test Metrics to Track**:
- Upload success rate (target: >98%)
- Average upload time by file size
- Processing completion rate (target: >95%)
- Gamification award success rate (target: >99.9%)
- RLS policy violation attempts (alert on any)
- Malware detection rate (baseline with test files)

**Alerts to Configure**:
- Upload failure rate > 5% (5-minute window)
- Processing stuck > 30 minutes
- Malware detected (immediate alert)
- RLS policy violation (immediate alert)
- Gamification retry queue depth > 100

---

## Summary

This comprehensive test design addresses all 18 identified risks from the risk profile, with heavy emphasis on:

1. **Security** (9 test scenarios) - Malware scanning, RLS policies, file enumeration, rate limiting
2. **Data Integrity** (6 test scenarios) - Backups, restoration, OCR validation
3. **Performance** (6 test scenarios) - Chunked uploads, concurrent load, polling efficiency
4. **Resilience** (8 test scenarios) - Retry logic, circuit breaker, network recovery

**Key Adaptations from Existing Code**:
- Extended `useFileUpload.tsx` with bank-statement-specific security
- Added UUID-based file paths (not timestamps)
- Implemented chunked uploads for large files
- Added backup strategy before processing
- Implemented retry queue for gamification failures

**Next Steps**:
1. Review and approve test design
2. Implement security enhancements (ClamAV integration)
3. Create test fixtures and environment
4. Execute P0 tests first
5. Address any failures before proceeding to P1/P2 tests
